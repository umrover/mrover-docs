---
title: "Light Detector"
---
**Context**: During the CIRC competition we must follow a series of red, blue, and infrared lights, while searching for crates labeled with AR tags. For full context consider reading the [CIRC Traversal Mission rules](https://circ.cstag.ca/2024/tasks/) or ask a lead for a verbal description.

**Problem**: We currently have no infrastructure for doing this task fully autonomously. Thus, you will devise a perception pipeline for detecting and publishing the locations of the lights, as well as design a algorithm which will traverse along these waypoints.

**Solution**: Use the ZED and perform a [thresholding algorithm](https://docs.opencv.org/3.4/d7/d4d/tutorial_py_thresholding.html) to locate the lights in image space. Then, using the point cloud generated by the ZED, estimate these objects in 3D space and add them to a cache. Upon each time a given location is detected with a light, increment a hitcounter. Once this counter goes beyond a threshold (will be determined with testing in sim and IRL) publish their locations to topic named `"light_poses"`.

<hr>

**Interface** (subject to change)

Node: `light_detector`

Subscribes: [sensor_msgs/PointCloud2](https://docs.ros.org/en/melodic/api/sensor_msgs/html/msg/PointCloud2.html) (ZED point cloud)

Publishes: Vector of [geometry_msgs/Vector3](http://docs.ros.org/en/noetic/api/geometry_msgs/html/msg/Vector3.html) (Array of Vector3)

Should Look Something Like this

`Vector3[] lights`

Rough Steps:
1. Use [OpenCV Thresholding](https://docs.opencv.org/4.x/db/d8e/tutorial_threshold.html) (over either RGB or HSV) to detect the lights in image space
2. Use [OpenCV Contours](https://docs.opencv.org/4.x/df/d0d/tutorial_find_contours.html) to determine light image space location
3. Use the ZED's point cloud to find the corresponding 3D point to the center of the detector light
4. Create a light cache with hit counts (probably using `std::unordered_map`)
5. Update hit counts as new lights are detected
6. Publish custom light position message to `"light_poses"`

Below is a diagram which shows the perception pipeline:
![Image](https://raw.githubusercontent.com/jbrhm/Assets/refs/heads/main/LightDetectorPipelineImage.jpg)